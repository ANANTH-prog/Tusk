{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deployment ML Project in Amazon Sagemaker",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMci1EQUjLHXeh9Ca2Adk4C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANANTH-prog/Tusk/blob/master/Deployment_ML_Project_in_Amazon_Sagemaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTmTGKquenU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing necessary buckets\n",
        "#Creating s3 bucket\n",
        "#Mapping Train and test Data in s3\n",
        "#Mapping the of model in s3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGRzG0KFe-Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
        "from sagemaker.session import s3_input, Session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuJF1b_pfDGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bucket_name = 'bankapplication' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
        "my_region = boto3.session.Session().region_name # set the region of the instance\n",
        "print(my_region)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l81R8qGdfDLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s3 = boto3.resource('s3')\n",
        "try:\n",
        "    if  my_region == 'us-east-1':\n",
        "        s3.create_bucket(Bucket=bucket_name)\n",
        "    print('S3 bucket created successfully')\n",
        "except Exception as e:\n",
        "    print('S3 error: ',e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT2m4rvkfDRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set an output path where the trained model will be saved\n",
        "prefix = 'xgboost-as-a-built-in-algo'\n",
        "output_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
        "print(output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD0YOTGOfVT3",
        "colab_type": "text"
      },
      "source": [
        "# ***Down loading the data set and storing in s3***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6arrj3wfDQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import urllib\n",
        "try:\n",
        "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
        "    print('Success: downloaded bank_clean.csv.')\n",
        "except Exception as e:\n",
        "    print('Data load error: ',e)\n",
        "\n",
        "try:\n",
        "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
        "    print('Success: Data loaded into dataframe.')\n",
        "except Exception as e:\n",
        "    print('Data load error: ',e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSDWIWUefDKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Train Test split\n",
        "\n",
        "import numpy as np\n",
        "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrjqUNe2fDE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Saving Train And Test Into Buckets\n",
        "## We start with Train Data\n",
        "import os\n",
        "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], \n",
        "                                                axis=1)], \n",
        "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
        "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J58XiRwSfxk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Test Data Into Buckets\n",
        "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
        "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC_ZtjNFfxuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
        "# specify the repo_version depending on your preference.\n",
        "container = get_image_uri(boto3.Session().region_name,\n",
        "                          'xgboost', \n",
        "                          repo_version='1.0-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdiEATL_fxym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize hyperparameters\n",
        "hyperparameters = {\n",
        "        \"max_depth\":\"5\",\n",
        "        \"eta\":\"0.2\",\n",
        "        \"gamma\":\"4\",\n",
        "        \"min_child_weight\":\"6\",\n",
        "        \"subsample\":\"0.7\",\n",
        "        \"objective\":\"binary:logistic\",\n",
        "        \"num_round\":50\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-_031-9fxtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct a SageMaker estimator that calls the xgboost-container\n",
        "estimator = sagemaker.estimator.Estimator(image_name=container, \n",
        "                                          hyperparameters=hyperparameters,\n",
        "                                          role=sagemaker.get_execution_role(),\n",
        "                                          train_instance_count=1, \n",
        "                                          train_instance_type='ml.m5.2xlarge', \n",
        "                                          train_volume_size=5, # 5 GB \n",
        "                                          output_path=output_path,\n",
        "                                          train_use_spot_instances=True,\n",
        "                                          train_max_run=300,\n",
        "                                          train_max_wait=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAbsNUEEfxin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator.fit({'train': s3_input_train,'validation': s3_input_test})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpN_MJcDgW43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VvE2dY7gbf9",
        "colab_type": "text"
      },
      "source": [
        "Deploy machine Learning Model as EndPoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBGm4EswgW-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amhtIU2eg2V9",
        "colab_type": "text"
      },
      "source": [
        "Prediction ofTestData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ6Xr12ngW9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sagemaker.predictor import csv_serializer\n",
        "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
        "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
        "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
        "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
        "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
        "print(predictions_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdF-Dwg2g-PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5XQoCXdg-Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
        "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
        "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
        "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
        "print(\"Observed\")\n",
        "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
        "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKdF83m6hPsF",
        "colab_type": "text"
      },
      "source": [
        "Deleting the End points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONDLiguQgW3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
        "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
        "bucket_to_delete.objects.all().delete()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}